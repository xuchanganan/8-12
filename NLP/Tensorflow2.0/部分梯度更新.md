# 预训练模型, 冷冻某些层. 
[参考](https://www.tensorflow.org/tutorials/images/transfer_learning)
```
from tensorflow import keras
import tensorflow as tf
# 伪数据
x_train = tf.random.uniform([100, 28, 28])
y_train = tf.random.uniform([100, 1], minval=0, maxval=10, dtype=tf.int32)
x_valid = tf.random.uniform([20, 28, 28])
y_valid = tf.random.uniform([20, 1], minval=0, maxval=10, dtype=tf.int32)

# 模型建立
model = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[28, 28]),
    keras.layers.Dense(300, activation='relu'),
    keras.layers.Dense(100, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])
model.build()
model.summary()

# 查看模型有多少层
model.trainable = True 
print("Number of layers in the base model: ", len(model.layers))

# 冷冻一些层(根据Layer所在层次)
fine_tune_at = 2
for layer in model.layers[:fine_tune_at]:  # 冻结'fine_tune_at'层之前的所有层
  layer.trainable =  False

# 查看冷冻后的结果
for layer in model.layers:
    print("layer_name = {}, layer_trainable = {}".format(layer.name, layer.trainable))
    

# 模型训练
model.compile(loss="sparse_categorical_crossentropy", optimizer = "sgd", metrics = ["accuracy"])
history = model.fit(x_train, y_train, epochs=20, validation_data=(x_valid, y_valid))
```

# 仅对部分参数进行更新
```
import matplotlib as mpl
import matplotlib.pyplot as plt
%matplotlib inline
import numpy as np
import sklearn
import pandas as pd
import os
import sys
import time
import tensorflow as tf
from tensorflow import keras



# 数据载入. 
fashion_mnist = keras.datasets.fashion_mnist
(x_train_all, y_train_all), (x_test, y_test) = fashion_mnist.load_data()
x_valid, x_train = x_train_all[:5000], x_train_all[5000:]
y_valid, y_train = y_train_all[:5000], y_train_all[5000:]



# 模型结构
class MyModel(tf.keras.Model):
    
    def __init__(self):
        super(MyModel, self).__init__()
        self.flatten = tf.keras.layers.Flatten(input_shape=[28, 28])
        self.dense1 = tf.keras.layers.Dense(300, activation='relu')
        self.dense2 = tf.keras.layers.Dense(100, activation='relu')
        self.dense3 = keras.layers.Dense(10, activation='softmax')
        
    def call(self, inputs, training=None):
        x = self.flatten(inputs) 
        embedded = self.dense1(x)
        x = self.dense2(embedded)
        x = self.dense3(x) 
        return x
    
    def build_graph(self, input_shape):   # 这样解决了, model.summary()输出 Output Shape = multiple的问题 
        input_shape_nobatch = input_shape[1:]
        self.build(input_shape)
        inputs = tf.keras.Input(shape=input_shape_nobatch)
        
        if not hasattr(self, 'call'):
            raise AttributeError("User should define 'call' method in sub-class model!")
        
        _ = self.call(inputs)

model = MyModel()
model.build_graph((None,28, 28))
model.layers       # 可以查看 layers. 
model.summary()


optimizer = tf.keras.optimizers.Adam()
train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')
loss_object = tf.keras.losses.SparseCategoricalCrossentropy()
def train_step(image, label):
    with tf.GradientTape() as tape:
        predictions = model(image,training=True)
        loss = loss_object(label, predictions)
    
    # 这里实现了, 仅对部分参数进行梯度更新. 
    gradients = tape.gradient(loss, model.dense2.trainable_variables)
        
    tf.print(gradients)

    optimizer.apply_gradients(zip(gradients, model.dense2.trainable_variables))  # 梯度更新. 

    train_accuracy(label, predictions)
```
