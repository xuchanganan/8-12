# 基本概念:  
- **单元状态**: 这是LSTM单元的内部单元状态(即记忆).    
- **隐藏状态**: 这是用于计算预测结果的外部隐藏状态.  
- **输入门**: 决定多少当前输入会被送入单元状态.  
- **遗忘门**: 决定多少先前的单元状态会被送到当前单元状态.  
- **输出门**: 决定多少单元状态被输出到隐藏状态.  

# 为什么能解决长期依赖问题?  
&emsp;&emsp;**在RNN中,单元状态总是随着每个到来的输入而改变,这导致RNN的单元状态总是改变.这种行为对于存储长期依赖关系是非常不利的**.  
&emsp;&emsp;因此LSTM配备了一种机制来保持单元状态不变(如果需要),使它们能够存储长期依赖关系.  
&emsp;&emsp;这是通过引入门控机制来实现的.**LSTM都有相应的门, 门在0和1之间是连续的(通常是sigmoid函数),其中,0表示没有信息流过该门,1表示所有信息都流过该门**。  

# LSTM如何解决梯度消失问题?  
&emsp;&emsp;RNN在使用基于时间的反向传播时,梯度会迅速减小,这使我们只能传播几个时间步的信息, 因此我们只能存储极少的时间步的信息, 从而只能拥有短期记忆。  
&emsp;&emsp;由权重W引起的梯度消失/爆炸相对容易解决, 可以进行权重初始化和采用梯度剪裁。  
&emsp;&emsp;见tf自然语言处理P151. 

