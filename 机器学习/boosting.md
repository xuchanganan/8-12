# 简介
&emsp;&emsp;分类问题中, 通过**改变训练样本的权重**, 学习多个分类器, 并将这些分类器进行线性组合, 提高分类的性能。  
<font color='red'>改变训练样本权重，其实就是在改变样本分布</font>  
- Adaboost提高那些被前一轮弱分类器错误分类样本的权值, 降低那些被正确分类样本的权值. 
- <font color='red'>[**加权多数表决**]</font>Adaboost加大分类误差率小的弱分类器的权值, 使其在表决中起较大作用, 减少分类误差率大的弱分类器的权值. 
# AdaBoost为什么能够提高学习精度?   
见训练误差分析.  

# 解释AdaBoost 
利用前向分步加法模型的角度解释.  

# 提升方法的思想
&emsp;&emsp; 强可学习和弱可学习(可学习，但结果仅比随机猜测略好)是等价的， 寻找弱可学习简单， 解决从弱可学习->强可学习, 因此提出了Boosting.  
