# 概述  
- Bagging  
&emsp;&emsp;每一次从原始数据中根据均匀概率分布有放回的抽取和原始数据大小相同的样本集合，样本点可能出现重复，
然后对每一次产生的训练集构造一个分类器，再对分类器进行组合。**常见的随机森林算法就是bagging的集成算法。**  

- boosting 
&emsp;&emsp;每一次抽样的样本分布都是不一样的，每一次迭代，都根据上一次迭代的结果，增加被错误分类的样本的权重，使得模型能
在之后的迭代中更加注意到难以分类的样本，这是一个不断学习的过程，也是一个不断提升的过程，这也是boosting思想的本质
